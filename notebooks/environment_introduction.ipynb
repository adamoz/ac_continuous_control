{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation in the Environment\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Start the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ac_continuous_control.environment import UnityEnvironmentWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# reacher_env = UnityEnvironmentWrapper(env_binary='../bin/reacher_single/Reacher.x86_64', train_mode=True)\n",
    "reacher_env = UnityEnvironmentWrapper(env_binary='../bin/reacher_multi/Reacher.x86_64', train_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains multiple agents that control robotic arms.  At each time step, agents control joints of arm with continuous actions. Action space has `4` dimensions  \n",
    "\n",
    "The state space has `33` dimensions.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 parallel worlds\n",
      "Number of actions: 4\n",
      "States look like:\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   7.90150833e+00  -1.00000000e+00\n",
      "   1.25147629e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -5.22214413e-01]\n",
      "States have length: 33\n"
     ]
    }
   ],
   "source": [
    "starting_states = reacher_env.reset()\n",
    "\n",
    "print(f'We have {reacher_env.num_agents} parallel worlds')\n",
    "\n",
    "action_size = reacher_env.action_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "print('States look like:\\n', starting_states[0])\n",
    "\n",
    "state_size = reacher_env.state_size\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: [ 0.          0.88999998  0.          0.          0.          0.          0.09\n",
      "  0.          0.          0.          0.17        0.          0.          0.06\n",
      "  0.25999999  0.67999998  0.44999999  0.          0.35999999  0.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_agents = reacher_env.num_agents\n",
    "action_size = reacher_env.action_size\n",
    "\n",
    "states = reacher_env.reset()                                  # reset env\n",
    "scores = np.zeros(num_agents)                                 # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size)        # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                         # all actions between -1 and 1   \n",
    "    \n",
    "    next_states, rewards, dones = reacher_env.step(actions)\n",
    "    scores += rewards                               \n",
    "    states = next_states\n",
    "    \n",
    "    if np.any(dones):\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reacher_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
